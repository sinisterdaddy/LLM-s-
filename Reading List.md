Readings on Large Language Models and Generative AI
Explore the cutting-edge world of Large Language Models (LLMs) and Generative AI through these curated readings:

Large Language Models:
Introduction to Large Language Models

Link
Dive into the fundamentals of LLMs, exploring their pre-training and fine-tuning for specific applications.
Language Models are Few-Shot Learners

Link
Delve into the research paper discussing how language models become few-shot learners, showcasing their adaptability.
Getting Started with LangChain + Vertex AI PaLM API

Link
A practical guide to using LangChain and the Vertex AI PaLM API for seamless integration.
Learn about LLMs, PaLM models, and Vertex AI

Link
Explore the capabilities of LLMs, PaLM models, and Vertex AI in this comprehensive guide.
Building AI-powered apps on Google Cloud databases using pgvector, LLMs, and LangChain

Link
Uncover how LLMs and LangChain contribute to building AI-powered applications on Google Cloud databases.
Training Large Language Models on Google Cloud

Link
A repository with examples for training large language models on Google Cloud, providing hands-on insights.
Prompt Engineering for Generative AI

Link
Understand the art and science of prompt engineering, a crucial aspect of effective generative AI.
PaLM-E: An embodied multimodal language model

Link
Explore the advancements in embodied multimodal language models with PaLM-E.
Parameter-efficient fine-tuning of large-scale pre-trained language models

Link
A deep dive into parameter-efficient fine-tuning methods for large-scale pre-trained language models.
Understanding Parameter-Efficient LLM Finetuning: Prompt Tuning And Prefix Tuning

Link
Gain insights into the nuances of parameter-efficient fine-tuning, specifically focusing on prompt tuning and prefix tuning.
Parameter-Efficient Fine-Tuning of Large Language Models with LoRA and QLoRA

Link
Explore the innovative approaches of LoRA and QLoRA in parameter-efficient fine-tuning.
Solving a machine-learning mystery

Link
Uncover the contextualization of large language models in the evolving landscape of machine learning.
Generative AI:
Background: What is a Generative Model?

Link
A foundational exploration of what constitutes a generative model and its implications.
Gen AI for Developers

Link
An in-depth resource for developers diving into the world of Generative AI on Google Cloud.
Ask a Techspert: What is generative AI?

Link
An interview-style piece demystifying generative AI, straight from the techsperts at Google.
What is generative AI?

Link
A McKinsey explainer providing a comprehensive overview of generative AI.
Building the most open and innovative AI ecosystem

Link
Explore Google Cloud's approach to fostering an open and innovative generative AI ecosystem.
Generative AI is here. Who Should Control It?

Link
A thought-provoking exploration of the ethical considerations surrounding the control of generative AI.
Stanford U & Googleâ€™s Generative Agents Produce Believable Proxies of Human Behaviors

Link
Uncover the collaboration between Stanford University and Google in producing believable proxies of human behaviors using generative agents.
Generative AI: Perspectives from Stanford HAI

Link
Gain insights from Stanford HAI's perspectives on the impact and future of generative AI.
Generative AI at Work

Link
A comprehensive working paper shedding light on the practical applications of generative AI.
The future of generative AI is niche, not generalized

Link
A forward-looking exploration of the specialized niches that will shape the future of generative AI.
The implications of Generative AI for businesses

Link
Deloitte's analysis on the implications of generative AI for businesses.
Proactive Risk Management in Generative AI

Link
Delve into the importance of proactive risk management in the responsible use of generative AI.
How Generative AI Is Changing Creative Work

Link
Harvard Business Review's exploration of the transformative impact of generative AI on creative processes.
Additional Resources:
Attention is All You Need

Link
Read the seminal paper introducing the attention mechanism, a crucial component in many language models.
Transformer: A Novel Neural Network Architecture for Language Understanding

Link
Explore the foundational blog post introducing the Transformer architecture for language understanding.
Transformer on Wikipedia

Link
A Wikipedia page providing comprehensive insights into the Transformer model.
What is Temperature in NLP?

Link
Understand the concept of temperature in Natural Language Processing (NLP) and its implications.
Model Garden

Link
Explore Google Cloud's Model Garden, a repository of pre-trained machine learning models and tools.
Auto-generated Summaries in Google Docs

Link
Learn about the integration of auto-generated summaries in Google Docs, showcasing the practical applications of language models.




